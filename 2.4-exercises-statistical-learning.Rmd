---
title: "2.4-exercises-statistical-learning"
author: "Kurt Schuepfer"
date: "1/24/2017"
output: html_document
---

##Conceptual

###1.
For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.

(a) The sample size n is extremely large, and the number of predictors p is small.
```{r}
#A more flexible model is preferred here. With an extremely large n, we can be confident that our estimates are precise. With a small set of features, we can afford to fit nuances in the pattern during estimation and be reasonably confident that it would generalize to the test set data. 
```

(b) The number of predictors p is extremely large, and the number of observations n is small.

```{r}
#In this case, I would expect flexible methods to fare less well. With a lower N, there is a larger standard error on the estimates, meaning less certainty about the shape of the data. Fitting the data tightly in such a scenario would be inviting high variance. 
```

(c) The relationship between the predictors and response is highly non-linear.

```{r}
#How to answer this depends on many factors, including sample size, underlying effect sizes to be estimates, etc. However, in general, assuming a well-powered sample, a flexible model would be preferred to accommodate the unique form of the function. Using a linear estimator on something non-linear, for example, would result in high bias. That said, non-linear patterns are still prone to overfitting, so one should always exercise caution. 
```

(d) The variance of the error terms, i.e. σ2 =Var(?), is extremely high

```{r}
#This scenario indicates that standard error is also extremely high. In these cases, we cannot be confident in the precision of our estimate. How to answer this question really depends on whether the high variance of error terms is attribuatble to a small sample size vs just a high standard deviation in the population. If the former, I'd err on the side of a robust, inflexible model, so as to acommodate a wider range of data patterns in the test set. But if the latter, I'd be agnostic about it. Here, the bias/variance tradeoff should be considered (and ideally measured with cross validation). 
```

###2. 
. Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide n and p.
(a) We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO salary.

```{r}
#regression, inference
#n = 500, p = 4
```

(b) We are considering launching a new product and wish to know whether it will be a success or a failure. We collect data on 20 similar products that were previously launched. For each product we have recorded whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables.

```{r}
#classification, prediction
#n = 20, p = 14
```

(c) We are interesting in predicting the % change in the US dollar in relation to the weekly changes in the world stock markets. Hence we collect weekly data for all of 2012. For each week we record the % change in the dollar, the % change in the US market, the % change in the British market, and the % change in the German market.

```{r}
#regression, prediction
#n = 52, p = 4
```

3. We now revisit the bias-variance decomposition.
(a) Provide a sketch of typical (squared) bias, variance, training er- ror, test error, and Bayes (or irreducible) error curves, on a single plot, as we go from less flexible statistical learning methods towards more flexible approaches. The x-axis should represent the amount of flexibility in the method, and the y-axis should represent the values for each curve. There should be five curves. Make sure to label each one.

```{r}
library(png)
img = readPNG("/Users/kurtschuepfer1/Downloads/ch2-3b.png")
img
```


(b) Explain why each of the five curves has the shape displayed in part (a).

```{r}
#Bias decreases with more flexible models, and tends to see lots of change at first before tapering off.

#Variance increases with more flexible models, and - like bias - there is a non-linear rate of change.

#The training error decreases with more flexibility because the tighter the model fits to the data, the lower the difference between observed and predicted values.

#The testing error shows a u-shape pattern, due to the bias-variance tradeoff. the model fares poorly on the one hand if there is too much bias injected into it. But on the other hand if the estimated function were too rigid, there would be high variance, due to overfitting.

#The irreducible error is constant (by definition, it is independent of the modeling)
```

###4.
You will now think of some real-life applications for statistical learning.
(a) Describe three real-life applications in which classification might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.

```{r}
#Predicting fraudulent checks. Predictors are demographics, marks on a check, etc. Outcome is whether a check was fraud. Prediction is the goal here, not necesarily inference.

#Predicting closings of a retail store. Predictors are demographics, season, economic health, etc. Outcome is whether the store will close vs not. The goal is prediction. 

#Estimating function to determine NCAA Final Four basketball teams. Predictors are performance metrics, home field advantage, scores of last few games, etc. Outcome is whether a team will make the Final Four vs not. The goal is inference, quantifying by how much home field advantage (and or other variables) increases the odds of a team making the final four. 

```

(b) Describe three real-life applications in which regression might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.

```{r}
#Predicting sales of a retail store. Predictors are demographics, season, economic health, etc. Outcome is sales. This is a prediction problem. 

#Predicting clicks on a webpage. Predictors are previous online click behavior, demographics, time of day, relevance of product to the consumer, etc. Outcome is # clicks. This is a prediction problem. 

#Estimate by how much seasonality affects gas bill. This is an inference problem, quantifying the value of the relationship between month and the gas bill.
```

(c) Describe three real-life applications in which cluster analysis might be useful.

```{r}
#Learning about certain 'types' of customers 
#Recommendation engines
#Image/pattern recognition
```

###5. 
What are the advantages and disadvantages of a very flexible (versus a less flexible) approach for regression or classification? Under what circumstances might a more flexible approach be preferred to a less flexible approach? When might a less flexible approach be preferred?

```{r}
#The advantage of a very flexible approach is that it approximates the true form very well (presuming it is non-linear). The disadvantages are that too much flexibility in the training data increases variance in the test data. A less flexible approach is preferred when the form of the true function is linear, when there is a small n, or when we'd want predictions to not necessarily be the most accurate, but the most reliable (consistent). 
```

###6. 
Describe the differences between a parametric and a non-parametric statistical learning approach. What are the advantages of a parametric approach to regression or classification (as opposed to a non- parametric approach)? What are its disadvantages?

```{r}
#Non-parametric doesn't impose a pre-defined shape on the data, where parametrics does (normal, Poission, etc.). Parametric approaches are useful for small n sample sizes or when abnormal shapes in the distributions render it unworkable (here we can't base our tests on the assumptions of parametric statistics, so we go towards rank-order non-parametric tests). 
```

###7. 
The table below provides a training data set containing six observations, three predictors, and one qualitative response variable.

Obs. X1 X2 X3 Y 
1     0  3 0  Red 
2     2  0 0  Red 
3     0  1 3  Red 
4     0  1 2  Green 
5    −1  0 1  Green 
6     1  1 1  Red

Suppose we wish to use this data set to make a prediction for Y when X1 = X2 = X3 = 0 using K-nearest neighbors.
(a) Compute the Euclidean distance between each observation and the test point, X1 = X2 = X3 =0.

```{r}
#3
#2
#3.15
#2.24
#1.41
#1.73
```

(b) What is our prediction with K =1? Why? (c) What is our prediction with K =3? Why?

```{r}
#With k = 1, green because with a value of 0, the data point is closest to observation 5, which is green.
#With k = 3, is is 2/3 probability of red, so red. 
```

(d) If the Bayes decision boundary in this problem is highly non- linear, then would we expect the best value for K to be large or small? Why?

```{r}
#We would expect small because with large area, there is a good chance of incorporating data points that may be unrelated. 
```

##Applied

###8. 
```{r}
library(ISLR)
setwd("~/Google Drive/Coursework/Year 5/STA567 Statistical Learning/islr-r-notes")
data <- read.csv("College.csv")
attach(data)
str(data)
head(data) #rownames just university names
rownames(data) <- data[,1]
data <- data[,-1]
fix(data)
head(data)

summary(data)
```

ii. Use the pairs() function to produce a scatterplot matrix of the first ten columns or variables of the data. Recall that you can reference the first ten columns of a matrix A using A[,1:10].

```{r}
pairs(data[,1:10])
```
iii. Use the plot() function to produce side-by-side boxplots of Outstate versus Private.

```{r}
boxplot(Outstate ~ Private)
library(ggplot2)
library(dplyr)
data %>% ggplot(aes(x = Private, y = Outstate)) + geom_boxplot()
```

iv. Create a new qualitative variable, called Elite,by binning the Top10perc variable. We are going to divide universities into two groups based on whether or not the proportion of students coming from the top 10% of their high school classes exceeds 50%.

```{r}
Elite=rep("No",nrow(data)) 
Elite[data$Top10perc >50]=" Yes"
Elite=as.factor(Elite)
data=data.frame(data ,Elite)
summary(data$Elite)
table(data$Elite)
```
Use the summary() function to see how many elite universities there are. Now use the plot() function to produce side-by-side boxplots of Outstate versus Elite.
v.Use the hist() function to produce some histograms with differing numbers of bins for a few of the quantitative variables. Youmay find the command par(mfrow=c(2,2)) useful: it will divide the print window into four regions so that four plots can be made simultaneously.Modifying the arguments to this function will divide the screen in other ways.

```{r}
ggplot(data, aes(x = Elite, y =Grad.Rate)) + geom_boxplot()
```

###9. 
9. This exercise involves the Auto data set studied in the lab. Make sure that the missing values have been removed from the data.
(a) Which of the predictors are quantitative, and which are qualitative?

```{r}
auto <- read.csv("Auto.csv")
str(auto)
nums <- sapply(auto, is.numeric)
auto.nums <- auto[,nums]
str(auto.nums)
```

(b) What is the range of each quantitative predictor? You can answer this using the range() function.
```{r}
sapply(auto.nums, range)
summary(auto.nums)
```

(c) What is the mean and standard deviation of each quantitative predictor?

```{r}
mean.sd <- function(x) c(mean = mean(x), sd = sd(x))
sapply(auto.nums, mean.sd)
```

(d) Now remove the 10th through 85th observations. What is the range, mean, and standard deviation of each predictor in the subset of the data that remains?

```{r}
auto.nums.sub <- auto.nums[-c(10:85),]
summary(auto.nums.sub)
mean.sd.range <- function(x) c(mean = mean(x), sd = sd(x), range = range(x))
sapply(auto.nums.sub, mean.sd.range)
```

(e) Using the full data set, investigate the predictors graphically, using scatterplots or other tools of your choice. Create some plots highlighting the relationships among the predictors. Comment on your findings.

```{r}
auto %>% ggplot(aes(x = cylinders, y = mpg, group = cylinders)) + geom_boxplot(aes(fill=cylinders))

auto %>% ggplot(aes(x = mpg, y = displacement)) + geom_point() + geom_smooth(method = "lm")
```

(f) Suppose that we wish to predict gas mileage (mpg) on the basis of the other variables. Do your plots suggest that any of the other variables might be useful in predicting mpg? Justify your answer.

```{r}
cor(auto.nums)
auto %>% ggplot(aes(x = cylinders, y = mpg, group = cylinders)) + geom_boxplot()
auto %>% ggplot(aes(x = displacement, y = mpg)) + geom_point() + geom_smooth(method = "lm")
auto %>% ggplot(aes(x = weight, y = mpg)) + geom_point() + geom_smooth(method = "lm")
auto %>% ggplot(aes(x = year, y = mpg)) + geom_point() + geom_smooth(method = "lm")

##All of the above look useful in predicting mpg
```

###10. 
Load the Boston data set from MASS package
```{r}
library(MASS)
attach(Boston)
str(Boston)
```

a) How many rows are in this data set? How many columns?What do the rows and columns represent?
```{r}
dim(Boston)
#506 rows represent suburbs 14 columns represent various demographics. 
```

(b) Make some pairwise scatterplots of the predictors (columns) in this data set. Describe your findings.

```{r}
pairs(Boston)

##There are many possible relationships to examine. The medv and rm relationship jumps out as particularly strong (and clearly linear)

cor(medv, rm)
```

(c) Are any of the predictors associated with per capita crime rate? If so, explain the relationship.

```{r}
cor(crim, Boston)

#The strongest correlations with crime rate appear to be indus, rad, tax, lstat

Boston %>% ggplot(aes(x = indus, y = crim)) + geom_point()
Boston %>% ggplot(aes(x = indus)) + geom_histogram(bins = 20, fill = "dark grey", color = "grey")

##The linear association of crim with indus appears to be driven by the second mode in a bimodal distribution.

Boston %>% ggplot(aes(x = rad, y = crim)) + geom_point() + geom_smooth(method = "lm")
Boston %>% ggplot(aes(x = rad)) + geom_histogram(bins = 20, fill = "dark grey", color = "grey")

##Again, there is a bimodal distribution to rad, explaining much of the association
cor(crim, rad)
##Subset with rad < 10 and re-test correlation
boston.lowrad <- Boston[rad < 10,]
cor(boston.lowrad$crim, boston.lowrad$rad)

Boston %>% ggplot(aes(x = tax)) + geom_histogram(bins = 20, fill = "dark grey", color = "grey")
Boston %>% ggplot(aes(x = lstat)) + geom_histogram(bins = 20, fill = "dark grey", color = "grey")
Boston %>% ggplot(aes(x = lstat, y = crim)) + geom_point() + geom_smooth(method = "lm")

```

(d) Do any of the suburbs of Boston appear to have particularly high crime rates? Tax rates? Pupil-teacher ratios? Comment on the range of each predictor.

```{r}
sapply(Boston, mean.sd.range)
upper.outlier.crit <- function(x) (mean(x) + 3*sd(x))
boston.high.crm <- subset(Boston, crim > upper.outlier.crit(crim))
boston.high.crm

boston.high.ptratio <- subset(Boston, ptratio > upper.outlier.crit(ptratio))
##Note, there are no outliers for ptratio and tax data (applying the 3 SD rule)
Boston %>% ggplot(aes(x = ptratio)) + geom_histogram(bins = 20, fill = "dark grey", color = "grey")

#obtain top 10
head(Boston[order(ptratio, decreasing = TRUE),], n=10)

boston.high.tax <- subset(Boston, tax > upper.outlier.crit(tax))
##Note, there are no outliers for ptratio and tax data (applying the 3 SD rule)
##But still a clear hump in the right tail... not showing up as outliers, due to large SD

Boston %>% ggplot(aes(x = tax)) + geom_histogram(bins = 20, fill = "dark grey", color = "grey")

boston.high.tax <- subset(Boston, tax > 600)
boston.high.tax
```

(e) How many of the suburbs in this data set bound the Charles river?

```{r}
sum(Boston$chas)
```

(f) What is the median pupil-teacher ratio among the towns in this data set?

```{r}
median(ptratio)
```

(g) Which suburb of Boston has lowest median value of owner-occupied homes? What are the values of the other predictors for that suburb, and how do those values compare to the overall ranges for those predictors? Comment on your findings.

```{r}
boston.lowest.medv <- (Boston[which(medv == min(medv)),])

sapply(boston.lowest.medv, mean.sd.range)
sapply(Boston, mean.sd.range)

##on average, low median value homes have higher crime, lower status, and higher nitrogen oxide concentrations
```

(h) In this data set, how many of the suburbs average more than seven rooms per dwelling? More than eight rooms per dwelling? Comment on the suburbs that average more than eight rooms per dwelling.
```{r}
sum(rm > 7)
sum(rm > 8)
boston.high.rm <- subset(Boston, rm > 8)
boston.high.rm
summary(boston.high.rm)
summary(Boston)

##Suburbs that average 8 rooms or more/hs have higher crime, higher median value, lower taxes
```
